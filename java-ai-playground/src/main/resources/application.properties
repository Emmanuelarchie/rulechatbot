server.port=${PORT:8080}
logging.level.org.atmosphere = warn
spring.mustache.check-template-location = false

# Launch the default browser when starting the application in development mode
vaadin.launch-browser=true

# Workaround for https://github.com/vaadin/hilla/issues/842
spring.devtools.restart.additional-exclude=dev/hilla/openapi.json
# To improve the performance during development.
# For more information https://vaadin.com/docs/flow/spring/tutorial-spring-configuration.html#special-configuration-parameters
vaadin.allowed-packages=com.vaadin,org.vaadin,dev.hilla,com.example.application
spring.jpa.defer-datasource-initialization = true

# LangChain4j properties
langchain4j.open-ai.streaming-chat-model.api-key=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
langchain4j.open-ai.streaming-chat-model.model-name=gpt-4-turbo
langchain4j.open-ai.streaming-chat-model.temperature=0
langchain4j.open-ai.embedding-model.api-key=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
langchain4j.open-ai.streaming-chat-model.strict-tools=true

# Logging properties
langchain4j.open-ai.streaming-chat-model.log-requests=true
langchain4j.open-ai.streaming-chat-model.log-responses=false
logging.level.dev.langchain4j=DEBUG
logging.level.dev.ai4j.openai4j=DEBUG
logging.level.ai.djl=OFF
